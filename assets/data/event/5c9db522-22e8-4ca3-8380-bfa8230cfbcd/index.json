{"hash":"1adf9648fa3212312732010af89986def5f36e0a","data":{"drupalNodeEvent":{"id":"5c9db522-22e8-4ca3-8380-bfa8230cfbcd","title":"大学沙龙 177期｜关于简约和自洽的原则：从人工智能到自然智能","field_starting_time":"2023-03-11T01:00:00+00:00","field_speakers":{"processed":"<p>主讲人：马毅。香港大学数据科学研究院首任院长，加州大学伯克利分校电子工程与计算机科学系教授。IEEE、ACM 和 SIAM会士。清华大学自动化和应用数学双学士，加州大学伯克利分校电子工程和数学双硕士、电子工程博士。研究兴趣包括计算机视觉、高维数据分析和集成智能系统。曾任微软亚洲研究院视觉计算组首席研究员和负责人，上海科技大学信息科学与技术学院执行院长。发表期刊论文60余篇，会议论文120篇，合著计算机视觉、广义PCA、高维数据分析方面教材三部。</p>\n\n<p>主持人：吕旭东。加州理工学院博士后研究员，Taihill Venture 创业合伙人。加州大学伯克利分校博士，北京大学物理学和经济学学士。</p>\n"},"field_organizers":{"processed":"<p>大学沙龙</p>\n"},"field_event_mode":"Online","field_event_language":"mandarin","field_event_record":true,"field_event_category":"Workshop","field_time_zone":"America/New_York","field_event_website":{"uri":"https://www.youtube.com/channel/UChnTf6-SqrxZWafWNuIiNjA"},"field_registration":true,"field_event_venue":"","field_description":{"processed":"<p>从神经网络和智能研究近 70 年的演进历程中，我们回顾过去 10 年深度网络和人工智能的革命。 从早期深度学习在判别任务（如语音识别和图像分类）中的成功到最近对生成任务（如图像生成和 ChatGPT）的关注，我们研究了当前人工智能方法成功背后的原因。<br />\n随着当前实践的局限性越来越明显，我们提出了一个新的理论框架，它既可以统一判别模型和生成模型的当前实践，又可以对现有的人工深度神经网络提供严格的数学解释。 流行的深度网络（例如，ResNet、CNN 或 Transformer）的架构和运算符都可以推导为展开优化方案，用于优化对感到世界所获习得表示的信息增益。为了确保优化表示的正确性或一致性，我们认为有必要通过“闭环”反馈和博弈来增加自我纠正和自我批评机制。 这自然会导致一个统一的计算框架，称为压缩闭环转录，它集成了信息论、控制/博弈论、稀疏编码和优化的基本思想。 我们认为，压缩闭环转录是一种通用的学习框架，可作为所有自主智能系统（无论是人工的还是自然的）的基本学习单元。搜索“大学沙龙”Youtube频道收看讲座。</p>\n"}}},"context":{}}